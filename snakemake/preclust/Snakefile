"""
    snakemake --keep-going -j 999999 --cluster "sbatch --exclude={cluster.exclude} -c {cluster.ntasks} -N {cluster.Nodes}  -t {cluster.runtime} -J {cluster.jobname} --mail-type={cluster.mail_type} --mail-user={cluster.mail}" --cluster-config cluster.json --configfile experimental_experiments.json --latency-wait 100 --verbose -n
    snakemake  --configfile experimental_experiments.json --latency-wait 100 --verbose -n
    snakemake --configfile experimental_experiments.json --latency-wait 100 --verbose --rerun-incomplete quality -n 
    snakemake --rulegraph --configfile experiments.json | dot -Tpng > figures/ruledag.png


    # preprocessing
    1. bax to bam
    2. subreads to ccs, to merged ccs
    3. ccs to demultiplexed ccs w/o barcodes (lima)

    # simulation
    4. Simlord
    5. adding of tags with "add_read_tags_to_bam.py"
    
    # algorithms
    3. demultiplexed ccs to isoseq3 cluster
    3'. (1) demultiplexed ccs (w. q values) and (2) the accessions of the flnc ccs reads produced by isoseq3 cluster to qt-clust (check if seqs have been altered!)

    # evaluation
    4. alignment of reads to hg38 (skip this if simulated data)
    5. Fix cluster-files produced by cluster and qt-clust to a unified format
    6. Run "compute_cluster_quality.py" and get various metrics

    # structure
    indata: 
    root folder: /nfs/brubeck.bx.psu.edu/scratch6/ksahlin/preclust_eval/
    bam_folder, ccs_folder, lima_folder, 
    isoseq3_folder, simlord_folder
    flnc_fastq_folder


    # target rules:
    preprocess 
    simulation
    cluster
    evaluation

"""

shell.prefix("set -o pipefail; ")
# configfile: "experiments.json"

####################################################
########## standard python functions ###############
####################################################

import re
import os
import errno
import shutil

def mkdir_p(path):
    print("creating", path)
    try:
        os.makedirs(path)
    except OSError as exc:  # Python >2.5
        if exc.errno == errno.EEXIST and os.path.isdir(path):
            pass
        else:
            raise

def parse_gnu_time(stderr_file):
    lines = open(stderr_file, 'r').readlines()
    print(lines)
    for l in lines:
        usertime_match =  re.search('User time \(seconds\): [\d.]+', l)
        wct_match = re.search('Elapsed \(wall clock\) time \(h:mm:ss or m:ss\): [\d.:]+', l) 
        mem_match = re.search('Maximum resident set size \(kbytes\): [\d.:]+', l) 
        if usertime_match:
            usertime = float(usertime_match.group().split(':')[1].strip())
        if wct_match:
            wallclocktime = wct_match.group().split()[7]
        if mem_match:
            mem_tmp = int(mem_match.group().split()[5])
            memory_gb = mem_tmp / 4000000.0 

    vals = list(map(lambda x: float(x), wallclocktime.split(":") ))
    if len(vals) == 3:
        h,m,s = vals
        tot_wallclock_secs = h*3600.0 + m*60.0 + s
    elif len(vals) == 2:
        m,s = vals
        tot_wallclock_secs = m*60.0 + s

    return usertime, tot_wallclock_secs, memory_gb


def read_fasta(fasta_file):
    fasta_seqs = {}
    k = 0
    temp = ''
    accession = ''
    for line in fasta_file:
        if line[0] == '>' and k == 0:
            accession = line[1:].strip().split()[0]
            fasta_seqs[accession] = ''
            k += 1
        elif line[0] == '>':
            yield accession, temp
            temp = ''
            accession = line[1:].strip().split()[0]
        else:
            temp += line.strip()
    if accession:
        yield accession, temp


def clean_dir(folder):
    keep_files = set(["final_candidates.fa", "cluster_report.csv", "cluster_summary.txt", "logfile.txt", "final_candidates_lq.fa"]) 
    for the_file in os.listdir(folder):
        if the_file in keep_files:
            continue

        file_path = os.path.join(folder, the_file)
        try:
            if os.path.isfile(file_path):
                os.unlink(file_path)
            elif os.path.isdir(file_path): 
                shutil.rmtree(file_path)
        except Exception as e:
            print(e)
#######################################


wildcard_constraints:
    dataset="[^/]+",
    sim_dataset="[^/]+",
    nr_reads="[^/]+"

############## TARGET FILES ####################

# PREPROCESS
TARGET_FILES = {}

def subreads_files(datasets):
    files = []
    for dataset in datasets:
        for movie in config[dataset]["movies"]:
            files.append(config["DATA"] + "{0}/subreads/{1}.subreads.bam".format(dataset, movie))
    return files


def ccs_files(datasets):
    files = []
    for dataset in datasets:
        for movie in config[dataset]["movies"]:
            files.append(config["DATA"] + "{0}/ccs/{1}.ccs.bam".format(dataset, movie))
    return files

def lima_files(datasets):
    files = []
    for dataset in datasets:
        for movie in config[dataset]["movies"]:
            files.append(config["DATA"] + "{0}/lima/{1}.demux.primer_5p--primer_3p.bam".format(dataset, movie))
    return files

# subreads_files = lambda dataset: expand(config["DATA"] + "{dataset}/subreads/{movie}.subreads.bam", dataset = dataset, movie = config[dataset]["movies"] )
# ccs_files = lambda wildcards: expand(config["DATA"] + "{dataset}/ccs/{movie}.ccs.bam", dataset = config["DATASET"], movie = config[wildcards.dataset]["movies"] )
# lima_files = lambda wildcards: expand(config["DATA"] + "{dataset}/lima/{movie}.lima.bam", dataset = config["DATASET"], movie = config[wildcards.dataset]["movies"])


TARGET_FILES['preprocess'] = subreads_files(config["REAL_DATASET"]) + ccs_files(config["REAL_DATASET"]) + lima_files(config["REAL_DATASET"])


#CLUSTER

isoseq3_real_files = expand(config["ROOT_OUT"] + "cluster/isoseq3/{dataset}/unpolished.{suffix}", dataset = config["REAL_DATASET"], suffix = ["bam", "cluster", "flnc.bam"]) 
# qt_qlust_files =
TARGET_FILES["cluster"] = isoseq3_real_files 

isoseq3_sim_files = expand(config["ROOT_OUT"] + "cluster/isoseq3/{sim_dataset}/{nr_reads}/unpolished.{suffix}", sim_dataset = config["SIM_DATASET"], nr_reads =config["NR_SIM_READS"], suffix = ["bam", "cluster", "flnc.bam"]) 
TARGET_FILES["cluster_sim"] = isoseq3_sim_files


#EVALUATION

eval_real_files = expand(config["ROOT_OUT"] + "evaluation/{dataset}/{tool}_table.tsv", dataset = config["REAL_DATASET"], tool = ["isoseq3", "qt_clust"]) 
TARGET_FILES["evaluation"] = eval_real_files 

#EVALUATION SIMULATED

eval_sim_files = expand(config["ROOT_OUT"] + "evaluation/{sim_dataset}/{nr_reads}/{tool}_table.tsv", sim_dataset = config["SIM_DATASET"],  nr_reads = config["NR_SIM_READS"], tool = ["isoseq3", "qt_clust"]) 
TARGET_FILES["evaluation_sim"] = eval_sim_files


# SIMULATE
simulate_files = expand(config["ROOT_OUT"] + "ccs/{sim_dataset}/{nr_reads}/ccs.bam" , sim_dataset = config["SIM_DATASET"], nr_reads =config["NR_SIM_READS"]) 
TARGET_FILES["simulation"] = simulate_files 

#EVALUATION SIMULATED



# rule all:
#     input:  TARGET_FILES["preprocess"], TARGET_FILES["simulation"], TARGET_FILES["cluster"], TARGET_FILES["evaluation"]

rule preprocess:
        input: TARGET_FILES["preprocess"]

# rule simulation:
#         input: TARGET_FILES["simulation"]

rule cluster:
        input: TARGET_FILES["cluster"]

rule cluster_sim:
        input: TARGET_FILES["cluster_sim"]

rule evaluation:
        input: TARGET_FILES["evaluation"]

rule evaluation_sim:
        input: TARGET_FILES["evaluation_sim"]

rule simulation:
        input: TARGET_FILES["simulation"]

#####################################################

rule bax2bam:
        input: #hdf5_files = config["RAW_DATA"] + "{batch_size}/{movie,*bax.h5}"
        output: bam_subreads = config["DATA"] + "{dataset}/subreads/{movie}.subreads.bam",
                bam_index = config["DATA"] + "{dataset}/subreads/{movie}.subreads.bam.pbi"
        run:
            pass
            # shell("bax2bam  $raw_path$movie\_s1_p0.1.bax.h5 $raw_path$movie\_s1_p0.2.bax.h5 $raw_path$movie\_s1_p0.3.bax.h5 -o {wildcards.dataset}/subreads/{wildcards.movie} ")


rule ccs:
    input: bam_subreads = rules.bax2bam.output.bam_subreads
    output: ccs_bam = config["DATA"] + "{dataset}/ccs/{movie}.ccs.bam",
            bam_index = config["DATA"] + "{dataset}/ccs/{movie}.ccs.bam.pbi",
    run:
        shell("ccs --minPasses=1 --numThreads=16 --polish {input.bam_subreads} {output.ccs_bam} ")


rule lima:
    input: ccs_reads = rules.ccs.output.ccs_bam, 
            primers = config["DATA"] + "{dataset}/primers.fasta"
    output: demultiplexed_ccs_reads = config["DATA"] + "{dataset}/lima/{movie}.demux.primer_5p--primer_3p.bam" 
    run:
        shell("source activate isoseq3")
        out = config["DATA"] + "{0}/lima/{1}.demux.bam".format(wildcards.dataset, wildcards.movie)
        shell("lima {input.ccs_reads} {input.primers} {out} --isoseq --no-pbi")


rule merge_demultiplexed_files:
    input: infiles = lambda wildcards: expand(rules.lima.output.demultiplexed_ccs_reads, dataset = wildcards.dataset, movie = config[wildcards.dataset]["movies"]) 
    output: outfile = config["ROOT_OUT"] + "ccs/{dataset}/ccs.bam" 
    
    run:
        shell("samtools merge {output.outfile} {input.infiles}")
        shell("pbindex {output.outfile}")


rule isoseq3_real:
    input:  ccs = rules.merge_demultiplexed_files.output.outfile
    output: time_and_mem = config["ROOT_OUT"] + "time_and_mem/isoseq3/{dataset}/runtime.stdout",
            clusters = config["ROOT_OUT"] + "cluster/isoseq3/{dataset}/unpolished.cluster",
            flnc = config["ROOT_OUT"] + "cluster/isoseq3/{dataset}/unpolished.flnc.bam",
            consensus = config["ROOT_OUT"] + "cluster/isoseq3/{dataset}/unpolished.bam"
    run:
        shell("source activate isoseq3")
        time = config["GNUTIME"]
        mkdir_p(config["ROOT_OUT"] + "time_and_mem/isoseq3/{0}/".format(wildcards.dataset) )
        mkdir_p(config["ROOT_OUT"] + "cluster/isoseq3/{0}/".format(wildcards.dataset) )
        shell("{time} isoseq3 cluster --num-threads 8 {input.ccs} {output.consensus} --verbose 2>&1 | tee {output.time_and_mem} ")

rule qt_clust_real:
    input:  flnc = rules.isoseq3_real.output.flnc,
            ccs = rules.merge_demultiplexed_files.output.outfile
    output: time_and_mem = config["ROOT_OUT"] + "time_and_mem/qt_clust/{dataset}/runtime.stdout",
            clusters = config["ROOT_OUT"] + "cluster/qt_clust/{dataset}/pre_clusters.csv"
    run:
        time = config["GNUTIME"]
        mkdir_p(config["ROOT_OUT"] + "time_and_mem/qt_clust/{0}/".format(wildcards.dataset) )
        outfolder = config["ROOT_OUT"] + "cluster/qt_clust/{0}/".format(wildcards.dataset)

        mkdir_p(outfolder)
        # python qt_qlust.py --flnc ~/tmp/simlord_simulated_ensembl_coding_seqs_chr22_w_extra_tags.fastq.bam --ccs ~/tmp/simlord_simulated_ensembl_coding_seqs_chr22_w_extra_tags.fastq.bam --outfolder ~/tmp/qt_clust_chr22_100k/ --t 4
        # time python  preclust3.py  --reads ~/Documents/data/iso-Seq/alzheimer/isoseq_flnc_300k.fastq  --outfolder ~/tmp/precluster3/alz_400kreads_debug_time_t4 --t 4
        shell("{time} /galaxy/home/ksahlin/prefix/source/isocon_nontargeted/modules/qt_clust.py --t 8 --flnc {input.flnc} --ccs {input.ccs}  --outfolder {outfolder}  2>&1 | tee {output.time_and_mem}")


rule simulate_dataset:
    input: 
        refs  = "/nfs/brubeck.bx.psu.edu/scratch6/ksahlin/data/ENSEMBLE_simulated/ensembl_coding_seqs.fa",
        sample_readlengths  = "/nfs/brubeck.bx.psu.edu/scratch6/ksahlin/preclust_eval/cluster/isoseq3/RC0_1cell_2017/unpolished.flnc.fastq",
        # qt_clust_predicted = rules.qt_clust.output.clusters
    output: 
        reads = config["ROOT_OUT"] + "ccs/{sim_dataset}/{nr_reads}/ccs.bam",
        fastq = config["ROOT_OUT"] + "ccs/{sim_dataset}/{nr_reads}/ccs.fastq",
        index = config["ROOT_OUT"] + "ccs/{sim_dataset}/{nr_reads}/ccs.bam.pbi"
    run:
        shell("source activate simlord")
        shell("which python")
        shell("python --version")
        shell("pip list")
        # refs = "/nfs/brubeck.bx.psu.edu/scratch6/ksahlin/data/ENSEMBLE_simulated/ensembl_coding_seqs.fa"
        # sample_readlengths = "/nfs/brubeck.bx.psu.edu/scratch6/ksahlin/preclust_eval/cluster/isoseq3/RC0_1cell_2017/unpolished.flnc.fastq"
        intermediate_reads = config["ROOT_OUT"] + "ccs/{0}/{1}/ccs".format(wildcards.sim_dataset, wildcards.nr_reads)
        shell("simlord --uniform-chromosome-probability --read-reference {input.refs} --sample-readlength-from-fastq {input.sample_readlengths}  -n {wildcards.nr_reads}  {intermediate_reads}")

        intermediate_bam = config["ROOT_OUT"] + "ccs/{0}/{1}/ccs_tmp.bam".format(wildcards.sim_dataset, wildcards.nr_reads)
        shell("samtools view -b {intermediate_reads}.fastq.sam > {intermediate_bam}")
        script_path = config["SCRIPT_FOLDER"] 


        shell("python {script_path}/add_read_tags_to_bam.py --inbam {intermediate_bam}  --outbam {output.reads}")
        shell("pbindex {output.reads}")


rule isoseq3_sim:
    input:  ccs = rules.simulate_dataset.output.reads
    output: time_and_mem = config["ROOT_OUT"] + "time_and_mem/isoseq3/{sim_dataset}/{nr_reads}/runtime.stdout",
            clusters = config["ROOT_OUT"] + "cluster/isoseq3/{sim_dataset}/{nr_reads}/unpolished.cluster",
            flnc = config["ROOT_OUT"] + "cluster/isoseq3/{sim_dataset}/{nr_reads}/unpolished.flnc.bam",
            consensus = config["ROOT_OUT"] + "cluster/isoseq3/{sim_dataset}/{nr_reads}/unpolished.bam"
    run:
        # shell("source activate isoseq3")
        time = config["GNUTIME"]
        mkdir_p(config["ROOT_OUT"] + "time_and_mem/isoseq3/{0}_{1}/".format(wildcards.sim_dataset, wildcards.nr_reads) )
        mkdir_p(config["ROOT_OUT"] + "cluster/isoseq3/{0}_{1}/".format(wildcards.sim_dataset, wildcards.nr_reads) )
        shell("{time} isoseq3 cluster --num-threads 8 {input.ccs} {output.consensus} --verbose 2>&1 | tee {output.time_and_mem} ")



rule qt_clust_sim:
    input:  flnc = rules.simulate_dataset.output.reads,
            ccs = rules.simulate_dataset.output.reads
    output: time_and_mem = config["ROOT_OUT"] + "time_and_mem/qt_clust/{sim_dataset}/{nr_reads}/runtime.stdout",
            clusters = config["ROOT_OUT"] + "cluster/qt_clust/{sim_dataset}/{nr_reads}/pre_clusters.csv"
    run:
        time = config["GNUTIME"]
        mkdir_p(config["ROOT_OUT"] + "time_and_mem/qt_clust/{0}/{1}/".format(wildcards.dataset, wildcards.nr_reads) )
        outfolder = config["ROOT_OUT"] + "cluster/qt_clust/{0}/{1}/".format(wildcards.dataset, wildcards.nr_reads)

        mkdir_p(outfolder)
        # python qt_qlust.py --flnc ~/tmp/simlord_simulated_ensembl_coding_seqs_chr22_w_extra_tags.fastq.bam --ccs ~/tmp/simlord_simulated_ensembl_coding_seqs_chr22_w_extra_tags.fastq.bam --outfolder ~/tmp/qt_clust_chr22_100k/ --t 4
        # time python  preclust3.py  --reads ~/Documents/data/iso-Seq/alzheimer/isoseq_flnc_300k.fastq  --outfolder ~/tmp/precluster3/alz_400kreads_debug_time_t4 --t 4
        shell("{time} /galaxy/home/ksahlin/prefix/source/isocon_nontargeted/modules/qt_clust.py --t 8 --flnc {input.flnc} --ccs {input.ccs}  --outfolder {outfolder}  2>&1 | tee {output.time_and_mem}")



rule minimap2_align_real:
    input:  reads = rules.isoseq3_real.output.flnc,
            ref = config["MMI"]
    output: fastq = "/nfs/brubeck.bx.psu.edu/scratch6/ksahlin/preclust_eval/read_alignment/{dataset}.fastq",
            alignment = "/nfs/brubeck.bx.psu.edu/scratch6/ksahlin/preclust_eval/read_alignment/{dataset}.sam"
    
    run:
        shell("bamtools convert -format fastq -in {input.reads} -out {output.fastq} ")
        shell("/usr/bin/time -v  minimap2 -t 8 -ax splice -uf -C5 {input.ref} {output.fastq} >  {output.alignment} ")

rule minimap2_align_sim:
    input:  reads = rules.simulate_dataset.output.reads,
            ref = config["MMI"]
    output: fastq = "/nfs/brubeck.bx.psu.edu/scratch6/ksahlin/preclust_eval/read_alignment/{sim_dataset}/{nr_reads}.fastq",
            alignment = "/nfs/brubeck.bx.psu.edu/scratch6/ksahlin/preclust_eval/read_alignment/{sim_dataset}/{nr_reads}.sam"
    
    run:
        shell("bamtools convert -format fastq -in {input.reads} -out {output.fastq} ")
        shell("/usr/bin/time -v  minimap2 -t 8 -ax splice -uf -C5 {input.ref} {output.fastq} >  {output.alignment} ")


rule file_convert_isoseq3_real_clusters:
    input: clusters = rules.isoseq3_real.output.clusters
    output: clusters = config["ROOT_OUT"] + "cluster/isoseq3/{dataset}/unpolished.mod_format.cluster",
    run:
        script_path = config["SCRIPT_FOLDER"]
        shell("python {script_path}/modify_cluster_format.py {input.clusters} {output.clusters} ")

rule file_convert_isoseq3_sim_clusters:
    input: clusters = rules.isoseq3_sim.output.clusters
    output: clusters = config["ROOT_OUT"] + "cluster/isoseq3/{sim_dataset}/{nr_reads}/unpolished.mod_format.cluster",
    run:
        script_path = config["SCRIPT_FOLDER"]
        shell("python {script_path}/modify_cluster_format.py {input.clusters} {output.clusters} ")

# rule file_convert_qt_clust_clusters:

rule v_measure_real:
    input: 
        true  = rules.minimap2_align_real.output.alignment,
        isoseq3_predicted  = rules.file_convert_isoseq3_real_clusters.output.clusters,
        qt_clust_predicted = rules.qt_clust_real.output.clusters
    output: 
        isoseq3_res = config["ROOT_OUT"] + "evaluation/{dataset}/isoseq3_table.tsv",
        qt_clust_res = config["ROOT_OUT"] + "evaluation/{dataset}/qt_clust_table.tsv"

    run:
        bam = "{0}.bam".format(input.true)
        shell("samtools view -b {input.true} > {bam}")
        sorted_bam = "{0}_sorted.bam".format(input.true)
        shell("samtools sort {bam} > {sorted_bam}")
        shell("samtools index {sorted_bam}")

        script_path = config["SCRIPT_FOLDER"]
        mkdir_p(config["ROOT_OUT"] + "evaluation/{0}/".format(wildcards.dataset))
        shell("source activate isoseq3")
        shell("which python")
        shell("python --version")
        shell("pip list")
        shell("python {script_path}/compute_cluster_quality.py --clusters {input.isoseq3_predicted} --classes {sorted_bam}  --outfile {output.isoseq3_res}")
        shell("python {script_path}/compute_cluster_quality.py --clusters {input.qt_clust_predicted} --classes {sorted_bam}  --outfile {output.qt_clust_res}")

rule v_measure_sim:
    input: 
        true  = rules.minimap2_align_sim.output.alignment,
        isoseq3_predicted  = rules.file_convert_isoseq3_sim_clusters.output.clusters,
        qt_clust_predicted = rules.qt_clust_sim.output.clusters
    output: 
        isoseq3_res = config["ROOT_OUT"] + "evaluation/{sim_dataset}/{nr_reads}/isoseq3_table.tsv",
        qt_clust_res = config["ROOT_OUT"] + "evaluation/{sim_dataset}/{nr_reads}/qt_clust_table.tsv"

    run:
        bam = "{0}.bam".format(input.true)
        shell("samtools view -b {input.true} > {bam}")
        sorted_bam = "{0}_sorted.bam".format(input.true)
        shell("samtools sort {bam} > {sorted_bam}")
        shell("samtools index {sorted_bam}")

        script_path = config["SCRIPT_FOLDER"]
        mkdir_p(config["ROOT_OUT"] + "evaluation/{0}_{1}/".format(wildcards.sim_dataset, wildcards.nr_reads))
        shell("source activate isoseq3")
        shell("which python")
        shell("python --version")
        shell("pip list")
        shell("python {script_path}/compute_cluster_quality.py --clusters {input.isoseq3_predicted} --classes {sorted_bam}  --outfile {output.isoseq3_res}")
        shell("python {script_path}/compute_cluster_quality.py --clusters {input.qt_clust_predicted} --classes {sorted_bam}  --outfile {output.qt_clust_res}")




# rule compute_clustering_metrics:
#     input: flnc = config["ROOT"]+"results/{EXPERIMENT_ID}/targeted/FLNC/{polish}_isoform_hits_{database}_hq.tsv", # rules.isoform_align_flnc.output.flnc_tsv,
#             isocon_hq = config["ROOT"]+"results/{EXPERIMENT_ID}/targeted/ISOCON/{polish}_isoform_hits_{database}_hq.tsv",
#             # isocon_lq = config["ROOT"]+"results/{EXPERIMENT_ID}/targeted/ISOCON/{polish}_isoform_hits_{database}_lq.tsv",
#             ice_hq = config["ROOT"]+"results/{EXPERIMENT_ID}/targeted/ICE_QUAL/unpolished_isoform_hits_{database}_hq.tsv",
#             # ice_hq = config["ROOT"]+"results/{EXPERIMENT_ID}/targeted/ICE_QUAL/{polish}_isoform_hits_{database}_hq.tsv",
#             # ice_lq = config["ROOT"]+"results/{EXPERIMENT_ID}/targeted/ICE_QUAL/{polish}_isoform_hits_{database}_lq.tsv"
#             proovread = config["ROOT"]+"results/{EXPERIMENT_ID}/targeted/PROOVREAD/{polish}_isoform_hits_{database}_hq.tsv"
#     output: isoforms_in_database_hq_plot = config["ROOT_OUT"]+"/results/{EXPERIMENT_ID}/targeted/{polish}_detected_in_{database}_hq.png",
#             # isoforms_in_database_hq_and_lq_plot = config["ROOT_OUT"]+"/results/{EXPERIMENT_ID}/targeted/{polish}_detected_in_{database}_lq_and_hq.png",
#             venn_diagram_hq = config["ROOT_OUT"]+"/results/{EXPERIMENT_ID}/targeted/{polish}_detected_in_{database}_hq_venn.png",
#             # venn_diagram_hq_and_lq = config["ROOT_OUT"]+"/results/{EXPERIMENT_ID}/targeted/{polish}_detected_in_{database}_lq_and_hq_venn.png"
#     run:
#         # python ../analysis/isoform_level/plot_isoform_hits.py --flnc ~/tmp/ISOFORM_ANALYSIS/07_22_17_CCS_POLISHED/pred_to_ref_best_alignments.tsv  --isocon ~/tmp/ISOFORM_ANALYSIS/07_22_17_ISOCON_polished_ccs/pred_to_ref_best_alignments.tsv --ice ~/tmp/ISOFORM_ANALYSIS/07_22_17_ICE_Q_polished_ccs/pred_to_ref_best_alignments.tsv  --outfolder ~/tmp/ISOFORM_ANALYSIS/results/identity_temp
#         # python perfect_matches_set_intersection.py ~/tmp/ISOFORM_ANALYSIS/results_all_high_qual_and_low_qual/identity_only_perfect_matches/hit_to_db.tsv  ~/tmp/ISOFORM_ANALYSIS/results_all_high_qual_and_low_qual/identity_only_perfect_matches/venn_diagram
        
#         script_folder = config["SCRIPT_FOLDER"]
#         db_transcripts = config[wildcards.database]
#         shell("python {script_folder}/plot_isoform_hits.py --flnc {input.flnc} --isocon {input.isocon_hq} --proovread {input.proovread} --ice {input.ice_hq} --database {db_transcripts} --outprefix {output.isoforms_in_database_hq_plot} ")
#         # shell("python {script_folder}/plot_isoform_hits.py --flnc {input.flnc} --isocon {input.isocon_hq} {input.isocon_lq} --ice {input.ice_hq} {input.ice_lq} --outprefix {output.isoforms_in_database_hq_and_lq_plot} ")
#         shell("python {script_folder}/perfect_matches_set_intersection.py {output.isoforms_in_database_hq_plot}_hit_to_db.tsv {output.venn_diagram_hq}")
#         # shell("python {script_folder}/perfect_matches_set_intersection.py {output.isoforms_in_database_hq_and_lq_plot}_hit_to_db.tsv {output.venn_diagram_hq_and_lq}")


# rule plot_number_passes:
#     input: ccs_bam = rules.ccs.output.ccs_bam
#     output: nr_passes_plot = config["ROOT"]+"results/{EXPERIMENT_ID}/{experiment}/{batch_size}_{polish}/nr_passes_plot.pdf"
#     run:
#         script_folder = config["SCRIPT_FOLDER"]
#         shell("python3 {script_folder}/nr_passes_plot.py  --bamfile {input.ccs_bam}  --outfile {output.nr_passes_plot}")
#     # python nr_passes_plot.py --bamfile ~/tmp/CCSTune/barcode_1-2kb_polished.ccs.bam --outfile ~/tmp/tpm_passes.pdf


